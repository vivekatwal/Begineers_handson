{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required Python Machine learning Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For preprocessing the data\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "# To split the dataset into train and test datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# To model the Gaussian Navie Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# To calculate the accuracy score of the model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "adult_df = pd.read_csv('adult.data',header = None, delimiter=' *, *', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add headers\n",
    "adult_df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "                    'marital_status', 'occupation', 'relationship',\n",
    "                    'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "                    'hours_per_week', 'native_country', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handling missing data\n",
    "adult_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output for above script\n",
    "\n",
    "age               0\n",
    "workclass         0\n",
    "fnlwgt            0\n",
    "education         0\n",
    "education_num     0\n",
    "marital_status    0\n",
    "occupation        0\n",
    "relationship      0\n",
    "race              0\n",
    "sex               0\n",
    "capital_gain      0\n",
    "capital_loss      0\n",
    "hours_per_week    0\n",
    "native_country    0\n",
    "income            0\n",
    "dtype: int64\n",
    "\n",
    "This shows that there is no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for value in ['workclass', 'education','marital_status', 'occupation','relationship','race', 'sex','native_country', 'income']:\n",
    "    print value,\":\", sum(adult_df[value] == '?')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output for above script\n",
    "\n",
    "workclass : 1836\n",
    "education : 0\n",
    "marital_status : 0\n",
    "occupation : 1843\n",
    "relationship : 0\n",
    "race : 0\n",
    "sex : 0\n",
    "native_country : 583\n",
    "income : 0\n",
    "\n",
    "The output of the above code snippet shows that there are 1836 missing values in workclass attribute. 1843 missing values in occupation attribute and 583 values in native_country attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# As we want to perform some imputation for missing values. Before doing that, we need some summary statistics of our dataframe. For this, we can use describe() method. It can be used to generate various summary statistics, excluding NaN values.\n",
    "adult_df_rev = adult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are passing an “include” parameter with value as “all”, this is used to specify that. we want summary statistics of all the attributes.\n",
    "# You check the basic statistics about the dataset after running the above command. You can spend some time here to get in details about each and ever stats provided.\n",
    "adult_df_rev.describe(include= 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Imputation Step\n",
    "# Now, it’s time to impute the missing values. Some of our categorical values have missing values i.e, “?”. We are going to replace the “?” with the above describe methods top row’s value. For example, we are going to replace the “?” values of workplace attribute with “Private” value.\n",
    "for value in ['workclass', 'education','marital_status', 'occupation','relationship','race', 'sex','native_country', 'income']:\n",
    "    adult_df_rev[value].replace(['?'], [adult_df_rev.describe(include='all')[value][2]],inplace='True')\n",
    "\n",
    "# We have performed data imputation step. You can check changes in dataframe by printing  adult_df_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For naive Bayes, we need to convert all the data values in one format. We are going to encode all the labels with the value between 0 and n_classes-1.\n",
    "# One-Hot Encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "workclass_cat = le.fit_transform(adult_df.workclass)\n",
    "education_cat = le.fit_transform(adult_df.education)\n",
    "marital_cat   = le.fit_transform(adult_df.marital_status)\n",
    "occupation_cat = le.fit_transform(adult_df.occupation)\n",
    "relationship_cat = le.fit_transform(adult_df.relationship)\n",
    "race_cat = le.fit_transform(adult_df.race)\n",
    "sex_cat = le.fit_transform(adult_df.sex)\n",
    "native_country_cat = le.fit_transform(adult_df.native_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize the encoded categorical columns\n",
    "adult_df_rev['workclass_cat'] = workclass_cat\n",
    "adult_df_rev['education_cat'] = education_cat\n",
    "adult_df_rev['marital_cat'] = marital_cat\n",
    "adult_df_rev['occupation_cat'] = occupation_cat\n",
    "adult_df_rev['relationship_cat'] = relationship_cat\n",
    "adult_df_rev['race_cat'] = race_cat\n",
    "adult_df_rev['sex_cat'] = sex_cat\n",
    "adult_df_rev['native_country_cat'] = native_country_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop the old categorical columns from dataframe\n",
    "dummy_fields = ['workclass', 'education', 'marital_status','occupation', 'relationship', 'race','sex', 'native_country']\n",
    "adult_df_rev = adult_df_rev.drop(dummy_fields, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For reindexing the columns, you can use the code snippet provided below:\n",
    "adult_df_rev = adult_df_rev.reindex_axis(['age', 'workclass_cat', 'fnlwgt', 'education_cat','education_num', 'marital_cat', 'occupation_cat',\n",
    "                                    'relationship_cat', 'race_cat', 'sex_cat', 'capital_gain',\n",
    "                                    'capital_loss', 'hours_per_week', 'native_country_cat', \n",
    "                                    'income'], axis= 1)\n",
    "\n",
    "adult_df_rev.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardization of Data\n",
    "num_features = ['age', 'workclass_cat', 'fnlwgt', 'education_cat', 'education_num',\n",
    "                'marital_cat', 'occupation_cat', 'relationship_cat', 'race_cat',\n",
    "                'sex_cat', 'capital_gain', 'capital_loss', 'hours_per_week',\n",
    "                'native_country_cat']\n",
    "\n",
    "scaled_features = {}\n",
    "for each in num_features:\n",
    "    mean, std = adult_df_rev[each].mean(), adult_df_rev[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    adult_df_rev.loc[:, each] = (adult_df_rev[each] - mean)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Slicing\n",
    "features = adult_df_rev.values[:,:14]\n",
    "target = adult_df_rev.values[:,14]\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,\n",
    "                                                                            target, test_size = 0.33, random_state = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes Implementation\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, target_train)\n",
    "target_pred = clf.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy of our Gaussian Naive Bayes model\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
